{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의\n"
      ],
      "metadata": {
        "id": "S15SJDjqdu0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `nn.Module` 상속 클래스 정의\n",
        "- `nn.Module`을 상속받는 클래스 정의\n",
        "- `__init__()`: 모델에서 사용될 모듈과 활성화 함수 등을 정의\n",
        "- `forward()`: 모델에서 실행되어야 하는 연산을 정의"
      ],
      "metadata": {
        "id": "Htl7QBbD5TQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZlmLXARtD-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c343b7zMtvG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `nn.Sequential`을 이용한 신경망 정의\n",
        "- `nn.Sequential` 객체로 그 안에 각 모듈을 순차적으로 실행\n",
        "- `__init__()`에서 사용할 네트워크 모델들을 `nn.Sequential`로 정의 가능\n",
        "- `forward()`에서 실행되어야 할 계산을 가독성 높게 작성 가능"
      ],
      "metadata": {
        "id": "7zt71U70uJ_V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OYDUzbxKu65r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSRl49H1u65r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파이토치 사전학습 모델\n",
        "\n",
        "* https://pytorch.org/vision/stable/models.html"
      ],
      "metadata": {
        "id": "Oubzn_vw3C6b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## 모델 파라미터\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 손실 함수(Loss function)\n",
        "\n",
        "* 예측 값과 실제 값 사이의 오차 측정\n",
        "* 학습이 진행되면서 해당 과정이 얼마나 잘 되고 있는지 나타내는 지표\n",
        "* 모델이 훈련되는 동안 최소화될 값으로 주어진 문제에 대한 성공 지표\n",
        "* 손실 함수에 따른 결과를 통해 학습 파라미터를 조정\n",
        "* 최적화 이론에서 최소화 하고자 하는 함수\n",
        "* 미분 가능한 함수 사용\n",
        "* 파이토치의 주요 손실 함수\n",
        "  - `torch.nn.BCELoss`: 이진 분류를 위해 사용\n",
        "  - `torch.nn.CrossEntropyLoss`: 다중 클래스 분류를 위해 사용\n",
        "  - `torch.nn.MSELoss`: 회귀 모델에서 사용"
      ],
      "metadata": {
        "id": "2EUJ4ZJqELiv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uV2LCfc6O9Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 옵티마이저(Optimizer)\n",
        "\n",
        "* 손실 함수를 기반으로 모델이 어떻게 업데이트되어야 하는지 결정 (특정 종류의 확률적 경사 하강법 구현)\n",
        "* optimizer는 `step()`을 통해 전달받은 파라미터를 모델 업데이트\n",
        "* 모든 옵티마이저의 기본으로 `torch.optim.Optimizer(params, defaults)` 클래스 사용\n",
        "* `zero_grad()`를 이용해 옵티마이저에 사용된 파라미터들의 기울기를 0으로 설정\n",
        "* `torch.optim.lr_scheduler`를 이용해 에포크(epochs)에 따라 학습률(learning rate) 조절\n",
        "* 파이토치의 주요 옵티마이저: `optim.Adadelta`, `optim.Adagrad`, `optim.Adam`, `optim.RMSprop`, `optim.SGD`"
      ],
      "metadata": {
        "id": "SNOk8dyWEF8O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f_RL2UDyE2mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fit4HLffPLC"
      },
      "source": [
        "<img src=\"https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F222B4F4F562BD0330EA41C\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습률 스케줄러(Learning rate scheduler)\n",
        "\n",
        "* 학습시 특정 조건에 따라 학습률을 조정하여 최적화 진행\n",
        "* 일정 횟수 이상이 되면 학습률을 감소(decay)시키거나 전역 최소점(global minimum) 근처에 가면 학습률을 줄이는 등\n",
        "* 파이토치의 학습률 스케줄러 종류\n",
        "  - `optim.lr_scheduler.LambdaLR`: 람다(lambda) 함수를 이용해 그 결과를 학습률로 설정\n",
        "  - `optim.lr_scheduler.StepLR`: 단계(step)마다 학습률을 감마(gamma) 비율만큼 감소\n",
        "  - `optim.lr_scheduler.MultiStepLR`: `StepLR`과 비슷하지만 특정 단계가 아니라 지정된 에포크에만 감마 비율로 감소\n",
        "  - `optim.lr_scheduler.ExponentialLR`: 에포크마다 이전 학습률에 감마만큼 곱함\n",
        "  - `optim.lr_scheduler.CosineAnnealingLR`: 학습률을 코사인(cosine) 함수의 형태처럼 변화시켜 학습률일 커지기도 하고 작아지기도 함\n",
        "  - `optim.lr_scheduler.ReduceLROnPlateau`: 학습이 잘되는지 아닌지에 따라 동적으로 학습률 변화"
      ],
      "metadata": {
        "id": "An4MW3nvRU0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 지표(Metrics)\n",
        "\n",
        "* 모델의 학습과 테스트 단계를 모니터링"
      ],
      "metadata": {
        "id": "0Xl6nnl2hdr0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VZX6rncldbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZDfp2kwk42c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cQHBVJ9mAE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}