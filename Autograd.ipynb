{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "CvS06z327xzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## Autograd(자동미분)\n",
        "\n",
        "- `torch.autograd` 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "- `backprop`를 위해 미분값을 자동으로 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "`requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGROgrM0ebO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79459f0-49e8-4540-988a-ef8667040241"
      },
      "source": [
        "a = torch.randn(3, 3)\n",
        "a = a * 3\n",
        "print(a)\n",
        "print(a.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2870, -4.9706,  2.2936],\n",
            "        [-4.2513, -0.0085, -0.6666],\n",
            "        [ 2.2424, -0.1049, -5.6564]])\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "`requires_grad_(...)`는 기존 텐서의 `requires_grad` 값을 바꿔치기(`in-place`)하여 변경\n",
        "\n",
        "`grad_fn`: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True) # inplace\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a * a).sum()\n",
        "print(b)    # sum을 했다는걸 기록에 남김\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "id": "trZeGPnNgiLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9843b0-9928-4de5-d138-8cef7a432093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "tensor(85.6018, grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x790dc5f077f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNU-r9p0Rpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c228e42-bcc9-42f2-ac0c-86bce1855db2"
      },
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)  # gradient 추적하게\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6sQ4EB0UYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe55eb0-7ec6-42c6-b8e2-7af6455f8cef"
      },
      "source": [
        "y = x + 5\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_2iM-Zq0ZdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f3d7dc-2b8a-403b-8b39-733537ac2768"
      },
      "source": [
        "z = y * y\n",
        "out = z.mean()\n",
        "print(z, out)   # 곱에 대한 gradient function이 들어감"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[36., 36., 36.],\n",
            "        [36., 36., 36.],\n",
            "        [36., 36., 36.]], grad_fn=<MulBackward0>) tensor(36., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산이 완료된 후, `.backward()`를 호출하면 자동으로 역전파 계산이 가능하고, `.grad` 속성에 누적됨"
      ],
      "metadata": {
        "id": "FW2x4dnSa7hp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdoN9p-1kn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc28ea9a-f95f-4b13-8541-ee48ae802ea6"
      },
      "source": [
        "print(out)\n",
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`grad`: data가 거쳐온 layer에 대한 미분값 저장"
      ],
      "metadata": {
        "id": "eKshKwXua5SU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CixGTXbV1B9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99f1dc0-2b30-4fee-a68f-0843208bb587"
      },
      "source": [
        "print(x)\n",
        "print(x.grad)   # 미분값 : 1.3333"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n",
            "tensor([[1.3333, 1.3333, 1.3333],\n",
            "        [1.3333, 1.3333, 1.3333],\n",
            "        [1.3333, 1.3333, 1.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY63Mcc-1iNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254f6c90-0eab-487d-b8b6-84b1af5323f3"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "  y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1397.6150,   260.7005,  -421.8473], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPaVAbIT3gx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5dc4bb-569c-46a4-da2c-5e3e9d84fd47"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "`with torch.no_grad()`를 사용하여 기울기의 업데이트를 하지 않음\n",
        "\n",
        "기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad()`로 감싸면 기울기 계산은 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeIe5_Z3jVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93ce817-a6aa-4a77-b85d-c90d431b69b1"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  print((x ** 2).requires_grad)   # gradient 계산은 X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "`detach()`: 내용물(content)은 같지만 `require_grad`가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcth7Ew3l7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e68ea73-08ea-467e-f086-cf709b729453"
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()      # gradient 빼기\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())  # 같음. gradient가 있냐 없냐의 차이"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 예제\n",
        "\n",
        "- 계산 흐름 $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해 $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면 $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCW7dq9uB89T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0b9515-a47d-4ec3-ee19-4b89d03888a7"
      },
      "source": [
        "a = torch.ones(2, 2)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AyyGy49FLz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1a3ec0-4755-4ad5-a5da-751a2800c8e3"
      },
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.data)\n",
        "print(a.grad)\n",
        "print(a.grad_fn)    # a에는 계산한게 없음"
      ],
      "metadata": {
        "id": "snIgJF-Wl6xW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6fbbca-058b-46a2-97f2-108f19c65514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "$b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPt042iF9V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcf0c64-a0a4-4807-a9ab-3a2d086d600a"
      },
      "source": [
        "b = a + 2\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "$c = b^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDS6gP0GFZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cece05c5-4e0f-47e5-d312-15dad20aaad2"
      },
      "source": [
        "c = b ** 2\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynoiUywGSwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df32843-7d87-471b-bdb3-5e773a3f9292"
      },
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ryJon9GeMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186c0bcf-0293-46af-858d-f0e38a4b8fc0"
      },
      "source": [
        "print(out)\n",
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "a의 `grad_fn`이 None인 이유는 직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccI4vIWGgqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d063320-ba26-4aad-ee05-734b8303ed67"
      },
      "source": [
        "print(a.data)\n",
        "print(a.grad)\n",
        "print(a.grad_fn)    # a값에 계산한건 없으니까"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oka1mkadHq-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae58e418-c7c9-4214-d4d5-05455afc0874"
      },
      "source": [
        "print(b.data)\n",
        "print(b.grad)\n",
        "print(b.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "None\n",
            "<AddBackward0 object at 0x790ce46cc280>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-7222c1aec66c>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(b.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiYNajdLccUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec09128-bf3a-4f86-89f0-61112a518063"
      },
      "source": [
        "print(c.data)\n",
        "print(c.grad)\n",
        "print(c.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "None\n",
            "<PowBackward0 object at 0x790ce46ccac0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f6ca42a4f63f>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(c.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcLoMYite0vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480554e4-6676-4a65-ba30-de400a0c6534"
      },
      "source": [
        "print(out.data)\n",
        "print(out.grad)\n",
        "print(out.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36.)\n",
            "None\n",
            "<SumBackward0 object at 0x790ce465fe50>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-85e75c577388>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(out.grad)\n"
          ]
        }
      ]
    }
  ]
}